{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modelos de Regresion",
      "provenance": [],
      "authorship_tag": "ABX9TyPAi0IUABkr1bNbfHiFWUcA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CamiloE/Proyectos-Personales/blob/master/Modelos_de_Regresion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o03dv5xoEf-a",
        "colab_type": "text"
      },
      "source": [
        "# **Modelos de Regresion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgOJH-K9EnvX",
        "colab_type": "text"
      },
      "source": [
        "### Regresion Lineal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITT8-iFHEoN-",
        "colab_type": "text"
      },
      "source": [
        "Ajusta un modelo con los coeficientes $w=(w_1,w_2,...,w_n)$ y busca minimizar la siguiente función: \n",
        "\\begin{equation}\n",
        "  min \\frac{1}{N}\\sum_{i=1}^{N} (y_i-Xw)^2\n",
        "\\end{equation}\n",
        "Este modelo se caracteriza por tener bajo sesgo y una alta varianza. Su complejidad es la siguiente: \n",
        "\\begin{equation}\n",
        "  O(n_{samples}n_{feat}^2)\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5177ojOfEoiA",
        "colab_type": "text"
      },
      "source": [
        "### Ridge \n",
        "En este modelo regularizado lineal se le agrega un poco de sesgo al modelo por medio de una penalización $L2$ a los coeficientes con un parámetro alfa. \n",
        "\\begin{equation}\n",
        "  min \\frac{1}{N}\\sum_{i=1}^{N} (y_i-Xw)^2 + \\alpha \\sum w^2 \n",
        "\\end{equation}\n",
        "Este modelo se caracteriza por tener bajo sesgo y una alta varianza. Su complejidad es la siguiente: \n",
        "\\begin{equation}\n",
        "  O(n_{samples}n_{feat}^2)\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jm8hTV1gUqHb",
        "colab_type": "text"
      },
      "source": [
        "### Regresión SGD\n",
        "Implementa un aprendizaje de gradiente descendente que soporta distintos tipos de penalidad. Es ideal aplicarlo cuando hay más de $10000$ muestras para el entrenamiento. Es lineal y tiene una complejidad de \n",
        "\\begin{equation}\n",
        "  O(knp)\n",
        "\\end{equation}\n",
        "Donde $k$ es el número de iteraciones\n",
        "Donde $p$ es el número de coeficientes no nulos\n",
        "Donde $n$ es el número de muestras. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6F7IwqaXUqbt",
        "colab_type": "text"
      },
      "source": [
        "### Regresión kNN\n",
        "Basada en el algoritmo de clasificación, asigna a cada muestra del vecindario un peso igual de influyente. Es un modelo no lineal  y usando el método de fuerza bruta tiene una complejidad de \n",
        "\\begin{equation}\n",
        "  O(DN^2)\n",
        "\\end{equation}\n",
        "$D$ es el numero de dimensiones y $N$ el de muestras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuodP2Tfn2qI",
        "colab_type": "text"
      },
      "source": [
        "###  Decision Tree Regressor\n",
        "En este algoritmo se crean varios subsets para el entrenamiento y genera un árbol de condiciones dando al final los valores predecidos. Es no lineal y tiene una complejidad de \n",
        "\\begin{equation}\n",
        "  O(n_{samples}^2n_{features}log(n_{samples}))\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFxrH9PJUphG",
        "colab_type": "text"
      },
      "source": [
        "### SVM Regressor \n",
        "El método consiste en crear un hiperplano y un margen de separación en el caso de la clasificación. En la regresión se aplica usando el hiperplano como un ajuste a los puntos y solo se toman las muestras que estan en los márgenes de error. Es un modelo que de acuerdo al kernel puede ser lineal o no lineal. Tiene una complejidad de \n",
        "\\begin{equation}\n",
        "  O(n_{feat}n_{samples}^3)\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPKs9wM2n2ZZ",
        "colab_type": "text"
      },
      "source": [
        "### Regresion con Redes Neuronales \n",
        "El perceptron multicapa se puede aplicar con una función de activación identity. Es no lineal y tiene una complejidad de \n",
        "\\begin{equation}\n",
        "  O(nmh^koi)\n",
        "\\end{equation}\n",
        "$n$ numero  de muestras,\n",
        "$m$ numero  de características,\n",
        "$k$ numero  de capas,\n",
        "$h$ numero  de neuronas por capa,\n",
        "$o$ numero  de neuronas a la salida,\n",
        "$i$ numero  de iteraciones"
      ]
    }
  ]
}